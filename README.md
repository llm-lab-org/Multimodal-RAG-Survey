# From Text to Multimodality: A Survey on Multimodal Retrieval-Augmented Generation

This repository is designed to collect and categorize papers related to Multimodal Retrieval-Augmented Generation (RAG) according to our survey paper: [From Text to Multimodality: A Survey on Multimodal Retrieval-Augmented Generation](https://arxiv.org/abs/xxxxx). Given the rapid growth in this field, we will continuously update both the paper and this repository to serve as a resource for researchers working on future projects.

## Overview
![Figure]()

## Abstract
Large Language Models (LLMs) struggle with hallucinations and outdated knowledge due to their reliance on static training data. Retrieval-Augmented Generation (RAG) mitigates these issues by integrating external information, thereby enhancing factual grounding. Recent advances in Multimodal Learning have extended RAG to Multimodal RAG, incorporating multiple modalities such as text, images, audio, and video to improve generative models. However, cross-modal alignment and reasoning introduce unique challenges, distinguishing Multimodal RAG from its text-based counterpart and leaving room for improvement.
This survey offers a structured and comprehensive analysis of Multimodal RAG systems, covering methodologies, datasets, benchmarks, evaluation metrics, and innovations in retrieval, fusion, augmentation, and generation. We precisely review training strategies, robustness enhancements, and loss functions, while also exploring the diverse tasks and applications these systems support. 
Furthermore, we discuss open challenges and future research directions to support advancements in this evolving field. This survey provides a foundation for developing more capable and reliable AI systems by bridging the gap between unimodal RAG and multimodal generative systems.

## Citations
If you find our paper, code, data, or models useful, please cite the paper:
```

```

## Paper Collection
### RAG-related Surveys

[Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG](https://arxiv.org/abs/2501.09136)
[Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2312.10997)
[Benchmarking Large Language Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2309.01431)  
[Old IR Methods Meet RAG](https://dl.acm.org/doi/pdf/10.1145/3626772.3657935)  
[A Survey on Retrieval-Augmented Text Generation](https://arxiv.org/abs/2202.01110)  
[Graph Retrieval-Augmented Generation: A Survey](https://arxiv.org/abs/2408.08921)  
[A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models](https://arxiv.org/abs/2405.06211)  
[RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural Language Processing](https://arxiv.org/abs/2404.19543)  
[Retrieval Augmented Generation (RAG) and Beyond: A Comprehensive Survey on How to Make Your LLMs Use External Data More Wisely](https://arxiv.org/abs/2409.14924)  
[Searching for Best Practices in Retrieval-Augmented Generation](https://arxiv.org/abs/2407.01219)  
[Retrieval-Augmented Generation for Natural Language Processing: A Survey](https://arxiv.org/abs/2407.13193)  
[A Survey on Retrieval-Augmented Text Generation for Large Language Models](https://arxiv.org/abs/2404.10981)  
[Graph Retrieval-Augmented Generation for Large Language Models: A Survey](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4895062)  
[Trustworthiness in Retrieval-Augmented Generation Systems: A Survey](https://arxiv.org/abs/2409.10102)  

### Retrieval Strategies Advances
#### Maximum Inner Product Search (MIPS)

### Augmentation Technique

---
## Contact
If you have questions, please send an email to mahdi.abootorabi2@gmail.com or ...
